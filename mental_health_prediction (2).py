# -*- coding: utf-8 -*-
"""Mental Health Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AAPpWg-gRhkQIhbEYEy-K_qeCTP09Xab
"""

from google.colab import files
uploaded = files.upload()



import pandas as pd

df = pd.read_csv('Mental Health Dataset.csv')

# Example: Filling nulls
df.fillna(method='ffill', inplace=True)

# Encoding
df = pd.get_dummies(df, drop_first=True)

print(df.columns)

from sklearn.model_selection import train_test_split

# Replace with the correct target column
y = df['care_options_Yes']
X = df.drop(['care_options_Yes'], axis=1)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.ensemble import RandomForestClassifier
model = RandomForestClassifier()
model.fit(X_train, y_train)

from sklearn.metrics import classification_report, confusion_matrix

y_pred = model.predict(X_test)
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))

print(set(X.columns) & set([y.name]))

from sklearn.model_selection import GridSearchCV

param_grid = {
    'n_estimators': [100, 200],
    'max_depth': [4, 6, 8]
}

grid = GridSearchCV(RandomForestClassifier(), param_grid, cv=5)
grid.fit(X_train, y_train)
print(grid.best_params_)

from sklearn.model_selection import GridSearchCV
grid.best_params_

from sklearn.ensemble import RandomForestClassifier
model = RandomForestClassifier(max_depth=8, n_estimators=100)

from sklearn.ensemble import RandomForestClassifier
model = RandomForestClassifier(max_depth=8, n_estimators=100, random_state=42)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

best_params = grid.best_params_
final_model = RandomForestClassifier(**best_params, random_state=42)
final_model.fit(X_train, y_train)
y_final_pred = final_model.predict(X_test)

print(confusion_matrix(y_test, y_final_pred))
print(classification_report(y_test, y_final_pred))

# Assuming 'model' is already trained, and you have X_train, y_train

from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, RocCurveDisplay
import matplotlib.pyplot as plt
import seaborn as sns

# Predict on training data
y_train_pred = model.predict(X_train)
y_train_proba = model.predict_proba(X_train)[:, 1]

# Accuracy on training data
train_accuracy = accuracy_score(y_train, y_train_pred)
print(f"Training Accuracy: {train_accuracy:.4f}")

# Classification report
print("\nTraining Classification Report:")
print(classification_report(y_train, y_train_pred))

# Confusion matrix
train_conf_matrix = confusion_matrix(y_train, y_train_pred)
sns.heatmap(train_conf_matrix, annot=True, fmt='d', cmap='Greens')
plt.title('Training Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

# ROC-AUC on training data
train_roc_auc = roc_auc_score(y_train, y_train_proba)
print(f"Training ROC-AUC Score: {train_roc_auc:.4f}")

# ROC curve
RocCurveDisplay.from_estimator(model, X_train, y_train)
plt.title("Training ROC Curve")
plt.show()

import pandas as pd

# Load new data (replace 'new_data.csv' with your file)
new_data = pd.read_csv('Mental Health Dataset.csv')

# Preprocess new_data the same way as your training data
# Example: If you did one-hot encoding and dropped first category
new_data_processed = pd.get_dummies(new_data, drop_first=True)

# Make sure new_data_processed has the same columns as X_train used for training
# If some columns are missing in new_data_processed, add them with zeros
for col in X_train.columns:
    if col not in new_data_processed.columns:
        new_data_processed[col] = 0

# Reorder columns to match training data
new_data_processed = new_data_processed[X_train.columns]

# Predict using the trained model
predictions = model.predict(new_data_processed)
probabilities = model.predict_proba(new_data_processed)[:, 1]  # Probability of positive class

# Output results
output = new_data.copy()
output['Predicted_Label'] = predictions
output['Predicted_Probability'] = probabilities

print(output.head())  # Show first few predictions

import joblib
joblib.dump(model, 'mental_health_model.pkl')

import pandas as pd

# Define the columns of your dataset (excluding target)
columns = [
    'Timestamp', 'Gender', 'Country', 'Work Environment', 'Family History',
    'Benefits', 'Care Options', 'Leave', 'Mental Health Consequence',
    'Phys Health Consequence', 'Coworkers', 'Supervisor', 'Mental Health Interview',
    'Phys Health Interview', 'Mental Vs Physical', 'Obs Consequence', 'Comment'
]

# Single new entry as a list (your example)
new_entry = [
    '8/27/2014 12:53', 'Female', 'United States', 'Corporate', 'No', 'Yes',
    'Yes', '1-14 days', 'Yes', 'No', 'Yes', 'Medium', 'No', 'No', 'Yes', 'No', 'Not sure'
]

# Create DataFrame with a single row
new_df = pd.DataFrame([new_entry], columns=columns)

# --- Preprocessing ---

# 1. Drop Timestamp & Comment (usually non-predictive)
new_df = new_df.drop(['Timestamp', 'Comment'], axis=1)

# 2. Convert categorical variables (example: One-Hot Encoding)
# Note: Your training data used pd.get_dummies(drop_first=True), so do the same

new_df_processed = pd.get_dummies(new_df, drop_first=True)

# 3. Add missing columns that your model expects but are not in this new entry
for col in X_train.columns:
    if col not in new_df_processed.columns:
        new_df_processed[col] = 0

# 4. Reorder columns to match training data
new_df_processed = new_df_processed[X_train.columns]

# 5. Predict with your trained model
prediction = model.predict(new_df_processed)[0]
probability = model.predict_proba(new_df_processed)[0,1]

print(f"Prediction: {'Needs Treatment' if prediction == 1 else 'No Treatment Needed'}")
print(f"Probability of needing treatment: {probability:.4f}")

import pandas as pd

# Step 1: Define the columns based on your dataset (excluding 'treatment' column if it's your label)
columns = [
    'Timestamp', 'Gender', 'Country', 'Work Environment', 'Family History',
    'Benefits', 'Care Options', 'Leave', 'Mental Health Consequence',
    'Phys Health Consequence', 'Coworkers', 'Supervisor',
    'Mental Health Interview', 'Phys Health Interview',
    'Mental Vs Physical', 'Obs Consequence', 'Comments'
]

# Step 2: Input the row data
new_entry = [
    '8/27/2014 15:22', 'Female', 'United States', 'Corporate', 'No', 'Yes',
    'Yes', '1-14 days', 'Yes', 'No', 'Yes', 'Medium', 'No', 'No', 'Yes', 'No', 'No'
]

# Step 3: Create a single-row DataFrame
new_df = pd.DataFrame([new_entry], columns=columns)

# Step 4: Drop unused columns (you likely didn't use 'Timestamp' or 'Comments' in training)
new_df = new_df.drop(['Timestamp', 'Comments'], axis=1)

# Step 5: One-hot encode (must match your training logic)
new_df_encoded = pd.get_dummies(new_df, drop_first=True)

# Step 6: Add missing columns from training
for col in X_train.columns:
    if col not in new_df_encoded.columns:
        new_df_encoded[col] = 0

# Step 7: Reorder columns to match training data
new_df_encoded = new_df_encoded[X_train.columns]

# Step 8: Make prediction
prediction = model.predict(new_df_encoded)[0]
probability = model.predict_proba(new_df_encoded)[0][1]

# Step 9: Print the result
result = 'Needs Mental Health Treatment' if prediction == 1 else 'Does NOT Need Mental Health Treatment'
print(f"ðŸ§  Prediction: {result}")
print(f"ðŸ“Š Probability of needing treatment: {probability:.4f}")